# –õ–µ–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä (../src/lexer.rs)

–ú–æ–¥—É–ª—å [`../src/lexer.rs`](../src/lexer.rs) —Ä–µ–∞–ª–∏–∑—É–µ—Ç –ª–µ–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä (–ª–µ–∫—Å–µ—Ä) –¥–ª—è —è–∑—ã–∫–∞ SOFIA. –õ–µ–∫—Å–µ—Ä –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞ —Å–∏–º–≤–æ–ª–æ–≤ (–∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞) –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –∑–∞—Ç–µ–º –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–º (–ø–∞—Ä—Å–µ—Ä–æ–º).

## üí° –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –º–æ–¥—É–ª—è

```mermaid
graph TD
    A[–ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥] --> B(Lexer);
    B --> C{–¢–æ–∫–µ–Ω—ã};
    C -- ../src/token.rs --> D[TokenType –∏ Token];
```

## üì¶ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ `Lexer`

–°—Ç—Ä—É–∫—Ç—É—Ä–∞ [`Lexer`](../src/lexer.rs:4) —Ö—Ä–∞–Ω–∏—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ª–µ–∫—Å–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞.

### –ü–æ–ª—è

- `input`: [`Vec<char>`](../src/lexer.rs:5) ‚Äî –í—Ö–æ–¥–Ω–æ–π –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥, –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä–æ–º —Å–∏–º–≤–æ–ª–æ–≤.
- `position`: [`usize`](../src/lexer.rs:6) ‚Äî –¢–µ–∫—É—â–∞—è –ø–æ–∑–∏—Ü–∏—è –≤ `input`, —É–∫–∞–∑—ã–≤–∞—é—â–∞—è –Ω–∞ —Å–∏–º–≤–æ–ª, –∫–æ—Ç–æ—Ä—ã–π –≤ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è.
- `read_position`: [`usize`](../src/lexer.rs:7) ‚Äî –°–ª–µ–¥—É—é—â–∞—è –ø–æ–∑–∏—Ü–∏—è –¥–ª—è —á—Ç–µ–Ω–∏—è –≤ `input` (—Å–∏–º–≤–æ–ª –ø–æ—Å–ª–µ `ch`).
- `ch`: [`char`](../src/lexer.rs:8) ‚Äî –¢–µ–∫—É—â–∏–π —Å–∏–º–≤–æ–ª, –∫–æ—Ç–æ—Ä—ã–π –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è.

## üõ†Ô∏è –ü—É–±–ª–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã

### `new`

```rust
pub fn new(input: String) -> Self
```

–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä [`Lexer`](../src/lexer.rs:13) –∏–∑ –∑–∞–¥–∞–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ª–µ–∫—Å–µ—Ä–∞ –∏ —Å—á–∏—Ç—ã–≤–∞–µ—Ç –ø–µ—Ä–≤—ã–π —Å–∏–º–≤–æ–ª.

- **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**

  - `input`: [`String`](../src/lexer.rs:13) ‚Äî –°—Ç—Ä–æ–∫–∞, —Å–æ–¥–µ—Ä–∂–∞—â–∞—è –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.

- **–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:**
  - `Self` ([`Lexer`](../src/lexer.rs:13)) ‚Äî –ù–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ª–µ–∫—Å–µ—Ä–∞.

### `next_token`

```rust
pub fn next_token(&mut self) -> Token
```

–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ª–µ–∫—Å–µ—Ä–∞, –∫–æ—Ç–æ—Ä—ã–π —Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω –∏–∑ –≤—Ö–æ–¥–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞. –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ–±–µ–ª—ã –∏ –æ–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –∞ –∑–∞—Ç–µ–º –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Ç–æ–∫–µ–Ω–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–µ–≥–æ —Å–∏–º–≤–æ–ª–∞ –∏, –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏, —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–∏–º–≤–æ–ª–∞.

- **–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:**
  - [`Token`](../src/token.rs:75) ‚Äî –°–ª–µ–¥—É—é—â–∏–π —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω.

## üîí –ü—Ä–∏–≤–∞—Ç–Ω—ã–µ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã

- `read_char(&mut self)`: –°—á–∏—Ç—ã–≤–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π —Å–∏–º–≤–æ–ª –∏–∑ –≤—Ö–æ–¥–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞ –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç `position`, `read_position` –∏ `ch`.
- `peek_char(&self) -> char`: "–ü–æ–¥–≥–ª—è–¥—ã–≤–∞–µ—Ç" —Å–ª–µ–¥—É—é—â–∏–π —Å–∏–º–≤–æ–ª –≤–æ –≤—Ö–æ–¥–Ω–æ–º –ø–æ—Ç–æ–∫–µ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–π –ø–æ–∑–∏—Ü–∏–∏. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –º–Ω–æ–≥–æ—Å–∏–º–≤–æ–ª—å–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `==`, `!=`, `**`, `&&`, `||`, `..`).
- `skip_whitespace(&mut self)`: –ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ –ø—Ä–æ–±–µ–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –¥–æ –ø–µ—Ä–≤–æ–≥–æ –Ω–µ–ø—Ä–æ–±–µ–ª—å–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞.
- `skip_comments(&mut self)`: –ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç –æ–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å `//`.
- `is_comment_start(&self) -> bool`: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—É—â–∞—è –ø–æ–∑–∏—Ü–∏—è —Å `//`.
- `read_identifier(&mut self) -> String`: –°—á–∏—Ç—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∏–º–≤–æ–ª–æ–≤, —Ñ–æ—Ä–º–∏—Ä—É—é—â–∏—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏–ª–∏ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ.
- `read_number(&mut self) -> String`: –°—á–∏—Ç—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∏–º–≤–æ–ª–æ–≤, —Ñ–æ—Ä–º–∏—Ä—É—é—â–∏—Ö —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω—ã–π –ª–∏—Ç–µ—Ä–∞–ª.
- `read_string(&mut self) -> Token`: –°—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç—Ä–æ–∫–æ–≤—ã–π –ª–∏—Ç–µ—Ä–∞–ª, –∑–∞–∫–ª—é—á–µ–Ω–Ω—ã–π –≤ –∫–∞–≤—ã—á–∫–∏.
- `is_letter(&self) -> bool`: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—É—â–∏–π —Å–∏–º–≤–æ–ª –±—É–∫–≤–æ–π –∏–ª–∏ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–µ–º.
- `is_digit(&self) -> bool`: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—É—â–∏–π —Å–∏–º–≤–æ–ª —Ü–∏—Ñ—Ä–æ–π.
- `lookup_ident(ident: &str) -> TokenType`: –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—á–∏—Ç–∞–Ω–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–æ–º —è–∑—ã–∫–∞ SOFIA, –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π [`TokenType`](../src/token.rs:3).

## üìù –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

```rust
use crate::lexer::Lexer;
use crate::token::{Token, TokenType};

let input = "let x = 10;".to_string();
let mut lexer = Lexer::new(input);

let token1 = lexer.next_token();
assert_eq!(token1.token_type, TokenType::Let);
assert_eq!(token1.literal, "let");

let token2 = lexer.next_token();
assert_eq!(token2.token_type, TokenType::Ident);
assert_eq!(token2.literal, "x");

let token3 = lexer.next_token();
assert_eq!(token3.token_type, TokenType::Assign);
assert_eq!(token3.literal, "=");

let token4 = lexer.next_token();
assert_eq!(token4.token_type, TokenType::Int);
assert_eq!(token4.literal, "10");

let token5 = lexer.next_token();
assert_eq!(token5.token_type, TokenType::Semicolon);
assert_eq!(token5.literal, ";");

let token6 = lexer.next_token();
assert_eq!(token6.token_type, TokenType::Eof);
assert_eq!(token6.literal, "");
```
